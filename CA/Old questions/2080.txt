DMA:
data transfer between peripherals and memory without interaction of CPU
CPU relinquishes control of memory bus, free to perform other tasks
peripherals manage mermory bus dorectly

DMA controller:
hardware for transferring data between peripherals and main memory rith
minimal interventin from cpu
3 registers
-address register:specifies desried memory location incremented after each
word is transferred between memory
-word count: no. of words to be transferred, decremented after each word is
transferred until 0=>ends of transfer. BG from cpu is made low and cpu
contines exexuting prevoious instruction
-control: species mode of transfer(read/write)

block diagram:
registers of controller are selected by cpu through address bus by
enabling DS RS input signal
RD WR are bidirectinonal
BR=1; cpu terminates execution of current isntruction and relinquesh mem bus
BG=0; cpu communicates with dma registers thorugh data bus and 
activating RD WR as niput lines
BG=1; dma directly communicates with memory by specifiying address in
address bus and activating RD WR as output lines
BR=0; dma complte

arithmetic overflow:
occurs when result of arithmetic operation exceeds range that can be
represented with available number of bits in a system
usually occurs in add,sub with signed numbers
range for 8 bit signed numbers = -128 to +127
+127+1=-128 due to overflwo but exoected +128

detection:
2 +ve sum=-ve
2 -ve sum=+ve
(a[msb]==b[msb]) and (sum[msb!=a[msb])
hardware: carry into MSB XOR carry out of MSB

microprogram sequencer:
part of microprogrammed CU that generates address of next micro instruction
to be executed from control memeory
input logic has 3 inputs I0 I1 supplied by branch fieled of control
mermory and T(test) by mux2. its output s0 s1 is supplied as select lines
for mux1 and L(load) to SBR(subroutine register)
mux 1 has 4 inputs, external MAP(memort addres pointer),sbr,addres field
of conrtol memory and increment, selecets one and store in control address
register(car)
mux2 input 1 i s z select line from condition field of CM

cache memory:
small high speed memory located between cpu and main memory ram
stores copies of frequently accessed data/instruc so cpu can access them
faster than fetching from ram
recude average memory access time, improvign system performance

elements of cachce desing:
cache size:
total amount of data cacha can hold
affects hit rate and cost

block size:
amoutn of data transferred at once

mapping function:
how memory blocks are placed in achce
direct: particular block of main memory placed in particular cache line
associative: block of main memory placed in any cache line
set associative: cache is divided into sets, each main memory blcok mapped
to one set but inside the set, it can go to any line
replacement policy:
if cache is full, decides which block to replace
direct:no policy as no choice of block palcement
associativee: replace cells of cache in fifo policy
set associative: random replacement, fifo or lru(least recently used)

write policy:
how writes to memory are handles
cache hit operation:
cpu issues read/write requests 
if requested word exists in cache, read/write is performed in cache (hit)

hit case:
in read, main memory isnt involved
in write
-cache and main memory are updated simulatenou(write through)
-update only cache location, mark it as dirty/modified bit then update
main memory location at time of cache block removal(write/copy back)

read miss case:
if requested word isnt in cache
-entire block of word contaiging requested word is copied from main memory
to cache and particular word is sent to cpu from cache (load through)
-reuqested word from memory is sent to cpu frist then cache is updated
(early restart)

write miss case:
if requested word is not in cache
-if write throuh, info is directly written to main memory
-if write back, block containg word brought to cache then word is overwritte
hit rate/mis rate:
higher hit rate=better performance

microoperations:
processor register place where data is held
register may contain instruction,address or data
operations on data in registers are microoperations

arithmetic microoperations:
add,sub,inc,dec,add with carry,sub with borrow,transfer/load

pipelining:
decompsoing a sequatial process into sub processes with each sub prcess
being executed in a special dedeicated segment that opertes concurrently
with aall other segments
each segment performs partial processing as specified by the way task
is partitioned. result obtained from copmutation in each segment is
transferred to next segment in pipelinle. the final result is obtained
after data has passed through all segments

pipeline hazards:
sistutaion thaht prevent next instruction in instruction stream from
execting during its desinagted cycel

structural/resource conflict:
access to memmory by 2 segmeetns at same time
with one memory port, data and instru fetch cant be initiated in same clock
sol: 
-using sperate instruction and data memory 
-stall pipeline

data/data dependency conflict:
instruction depends on result of previous instruction which isnt availabe ye
r1<-r2+r3
r5<-r1+r4

RAW:
instruction reads data before prev instr writes it
r1<-r2+r3
r5<-r1+r4

WAR:
inctruction writes to a register before prev instr reads from it
r4<-r1+r5
r5<-r1+r2

WAW:
2 instructions write to same location
r5<-r1+r3
r5<-r1+r2

sol:
-hardware interlock: hardware
hardware deects data dependcy then delays scheduling of dependent instr
by staaling enough clokc ycles

-operand forwarding: hardware
special hardware detects conflict then avoid it by routing data through
special path between pipeline segments

-delayed load: software
compiler detects data conflict and reorders instr to delay loading of 
conflicting data by inserting no operations instruc

control/branch conflict:
branch and other isntr that alter sequential program flow by loading pc
with target address

sol:
prefetch target instruction:
fetch intructio in both streams branch taken/not
when brnach is executed, select right sintruc stream and discard wrong

branch target buffer: btb
small associatve memory(cache) that stores previously executed brnach instr
along with branch address and if they were taken

loop buffer:
special small buffer that stores insdtruction of small loop

branch prediction:
predict outcome of a beanch taken/not taken before acutally resolved

delayed branch:
compiler moves useful isntruction immediately after branch which always
executes

X = (A+B*C-D)/(E*F+G)

0 address inst format:
used in stack based architecure
operaend are implicitly on top of stack
convert to postfix
push a
push b
push c
mul
add
push d
sub
push e
push f
mul
push g
add
div
pop x


1 address:
one explicit address, other is implicilty in accumulator
load b
mul c
add a
sub d
store r1
load e
mul f
add g
store r2
load r1
div r2
store x

2 address:
source and destination, one operand is overwritten
mov r1,b
mul r1,c
mov r2,a
add r2,r1
sub r2,d
mov r3,e
mul r3,f
add r3,g
div r2,r3
mov x,r2

3 address:
has 2 explciit address, 2 source 1 destination
mul r1,b,c
add r2,a,r1
sub r3,r2,d
mul r4,e,f
add r5,r4,g
div x,r3,r5

risc vs cisc:
risc 					cisc
ins set is small simple			ins set is large complex
ins length is fixed			ins length is varaible
exe speed is faster(one per cycle)	slower(multiple cycles)
specific ins load/store for memory acc	any instruction may access
larger code size			smaller code size
easy pipeline				harder pipeline
hardwired control unit			micro programmed CU
more data in regesters for less mem acc	more use of memort for less register
arm risc-v mips				interl x86 amd motorolla 608000

flynns classification:
organization of computer system by MJ Flynn based on no. of instruction
and data streams that are processed simultaneously
ins stream is sequuence of instr read from memory
data stream is operations performed on data in processor

sisd:
single computer containg 1 CU PU MU
instructions are executed equentially, system may not have paralel procesing
parallel processing is achceived by multiple functional units/pipelining
traditiional von neumann comcputers,older gen cmops,minicomp,workstations
instructions are decoded by CU nad sent to PU for execution

simd:
many PU under single CU
all processorts receive same instr from CU but operate on diferent data item
shared memory has multiple moduels to communicate with all prcoess simultan
wireless MMX unit by intel, GPU for image processing,scientific computing

misd:
theoritcal
mulitple processing unit operate on single data stream
each PU operates on data independently via spearpaete instru stream
real time system for reliability in aerospace

mimd:
multiple processor execute different instruction on different data
each processor has sperpate prgogram and instr stream is generated from it
cray t90,multi core CPU,distributed systems,cloud computing for general
pruppes parallel processing,multitasking environemnts

common bus sytem:
8 registers memory and control unit
path for transfer info between registser and moomery to register
o/p of regusters and memory connected t ocommon bus
s2 s1 s0 control which register/memory bus selects as input
